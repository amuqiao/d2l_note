import os
import sys
import time
import json
import datetime
import argparse
import torch
import os
from typing import List, Dict, Any, Optional

# å¯¼å…¥æ—¥å¿—å·¥å…·
from src.utils.log_utils.log_utils import get_logger

# åˆå§‹åŒ–æ—¥å¿—ï¼Œè®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
logger = get_logger(
    name="batch_train",
    log_file="logs/batch_train.log",  # æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºlogsç›®å½•
    global_level="DEBUG",     # å…¨å±€æ—¥å¿—çº§åˆ«
    console_level="INFO",     # æ§åˆ¶å°æ—¥å¿—çº§åˆ«ï¼ˆåªè¾“å‡ºINFOåŠä»¥ä¸Šï¼‰
    file_level="DEBUG"        # æ–‡ä»¶æ—¥å¿—çº§åˆ«ï¼ˆè¾“å‡ºæ‰€æœ‰çº§åˆ«ï¼‰
)


# è§£å†³OpenMPè¿è¡Œæ—¶åº“å†²çªé—®é¢˜
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹å¹¶æ³¨å†Œ
# æ³¨æ„ï¼šè¿™äº›å¯¼å…¥ä¼šè§¦å‘æ¨¡å‹çš„è‡ªåŠ¨æ³¨å†Œ
from src.models.lenet import LeNet, LeNetBatchNorm
from src.models.alexnet import AlexNet
from src.models.vgg import VGG
from src.models.nin import NIN
from src.models.googlenet import GoogLeNet
from src.models.resnet import ResNet
from src.models.dense_net import DenseNet
from src.models.mlp import MLP

from src.utils.model_registry import ModelRegistry
from src.trainer.trainer import Trainer
from src.utils.data_utils import DataLoader
from src.utils.visualization import VisualizationTool

class BatchTrainer:
    """æ‰¹é‡è®­ç»ƒå·¥å…·ç±»ï¼šç”¨äºæ‰¹é‡è®­ç»ƒæ‰€æœ‰å·²æ³¨å†Œçš„æ¨¡å‹"""
    
    def __init__(self, configs: Dict[str, Dict[str, Any]] = None, skip_models: List[str] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡è®­ç»ƒå™¨
        
        Args:
            configs: å¯é€‰çš„æ¨¡å‹é…ç½®å­—å…¸ï¼Œé”®ä¸ºæ¨¡å‹åç§°ï¼Œå€¼ä¸ºé…ç½®å‚æ•°
            skip_models: å¯é€‰çš„è·³è¿‡çš„æ¨¡å‹åç§°åˆ—è¡¨
        """
        self.configs = configs or {}
        self.skip_models = skip_models or []
        self.results = []
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        VisualizationTool.setup_font()
    
    def get_all_registered_models(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²æ³¨å†Œä¸”æœªè¢«è·³è¿‡çš„æ¨¡å‹"""
        all_models = ModelRegistry.list_models()
        return [model for model in all_models if model not in self.skip_models]
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çš„é…ç½®å‚æ•°"""
        # å¦‚æœç”¨æˆ·æä¾›äº†é…ç½®ï¼Œä½¿ç”¨ç”¨æˆ·çš„é…ç½®
        if model_name in self.configs:
            return self.configs[model_name]
        
        # å¦åˆ™ä½¿ç”¨æ¨¡å‹æ³¨å†Œä¸­å¿ƒçš„é»˜è®¤é…ç½®
        try:
            return ModelRegistry.get_config(model_name)
        except ValueError:
            # å¦‚æœæ²¡æœ‰é»˜è®¤é…ç½®ï¼Œè¿”å›ä¸€ä¸ªåŸºç¡€é…ç½®
            return {
                "num_epochs": 10,
                "lr": 0.01,
                "batch_size": 128,
                "resize": None,
                "input_size": (1, 1, 28, 28)  # é»˜è®¤LeNetå°ºå¯¸
            }
    
    def train_model(self, model_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        è®­ç»ƒå•ä¸ªæ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„è®­ç»ƒå™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
            config: è®­ç»ƒé…ç½®å‚æ•°
        
        Returns:
            è®­ç»ƒç»“æœå­—å…¸ï¼ˆåŒ…å«æˆåŠŸ/å¤±è´¥çŠ¶æ€å’Œè¯¦ç»†ä¿¡æ¯ï¼‰
        """
        # ç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„è®­ç»ƒå™¨æ‰§è¡Œè®­ç»ƒ
        enable_visualization = config.get("enable_visualization", False)
        save_every_epoch = config.get("save_every_epoch", False)
        
        # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
        trainer = Trainer()
        
        # ä½¿ç”¨è®­ç»ƒå™¨çš„run_trainingæ–¹æ³•æ‰§è¡Œè®­ç»ƒ
        result = trainer.run_training(
            model_type=model_name,
            config=config,
            enable_visualization=enable_visualization,
            save_every_epoch=save_every_epoch
        )
        
        # é¢å¤–çš„ä¿å­˜ç›®å½•ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦æ›´è¯¦ç»†çš„æ—¥å¿—ï¼‰
        if result["success"] and result.get("run_dir"):
            logger.info(f"ğŸ“ è®­ç»ƒç»“æœä¿å­˜ç›®å½•: {result['run_dir']}")
        
        self.results.append(result)
        return result
    
    def train_all_models(self) -> List[Dict[str, Any]]:
        """è®­ç»ƒæ‰€æœ‰å·²æ³¨å†Œçš„æ¨¡å‹ï¼Œç¡®ä¿å•ä¸ªæ¨¡å‹å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹"""
        models_to_train = self.get_all_registered_models()
        
        if not models_to_train:
            warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯è®­ç»ƒçš„æ¨¡å‹ï¼")
            return []
        
        logger.info(f"ğŸ“‹ å‘ç° {len(models_to_train)} ä¸ªå¯è®­ç»ƒçš„æ¨¡å‹ï¼š{', '.join(models_to_train)}")
        
        total_start_time = time.time()
        
        # ç¡®ä¿æ¯ä¸ªæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éƒ½è¢«ç‹¬ç«‹ä¿æŠ¤ï¼Œé˜²æ­¢ä¸€ä¸ªæ¨¡å‹çš„å¼‚å¸¸å½±å“æ•´ä¸ªå¾ªç¯
        for idx, model_name in enumerate(models_to_train, 1):
            try:
                logger.info(f"\nğŸ“Œ å¼€å§‹è®­ç»ƒç¬¬ {idx}/{len(models_to_train)} ä¸ªæ¨¡å‹: {model_name}")
                config = self.get_model_config(model_name)
                self.train_model(model_name, config)
                logger.info(f"âœ… æ¨¡å‹ {model_name} è®­ç»ƒå¤„ç†å®Œæˆ")
            except Exception as e:
                # è¿™æ˜¯é¢å¤–çš„å®‰å…¨ä¿éšœï¼Œé˜²æ­¢train_modelå†…éƒ¨çš„å¼‚å¸¸å¤„ç†å¤±æ•ˆ
                logger.error(f"âŒ æ¨¡å‹ {model_name} è®­ç»ƒè¿‡ç¨‹å‡ºç°ä¸¥é‡é”™è¯¯ï¼")
                logger.exception(f"ğŸ’¬ é”™è¯¯è¯¦æƒ…: {str(e)}")
                
                # è®°å½•è¿™ä¸ªä¸¥é‡é”™è¯¯
                self.results.append({
                    "model_name": model_name,
                    "best_accuracy": 0.0,
                    "training_time": 0,
                    "error": f"ä¸¥é‡å¼‚å¸¸: {str(e)}",
                    "config": config if 'config' in locals() else {},
                    "success": False
                })
                
                logger.info(f"ğŸ”„ ç»§ç»­è®­ç»ƒä¸‹ä¸€ä¸ªæ¨¡å‹...")
        
        total_time = time.time() - total_start_time
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼æ€»è®¡è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"{'='*60}")
        
        return self.results
    
    def save_results(self, output_path: str = None) -> str:
        """ä¿å­˜è®­ç»ƒç»“æœåˆ°æŒ‡å®šè·¯å¾„çš„JSONæ–‡ä»¶
        
        Args:
            output_path: ç»“æœä¿å­˜è·¯å¾„ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶åæˆ–ç›®å½•åã€‚å¦‚æœæ˜¯ç›®å½•åï¼Œåˆ™ä¼šåœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                        é»˜è®¤ä¿å­˜åœ¨æ ¹ç›®å½•ä¸‹çš„logç›®å½•
                        
        Returns:
            ä¿å­˜ç»“æœçš„å®Œæ•´æ–‡ä»¶è·¯å¾„
        """
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        
        # å¤„ç†é»˜è®¤æƒ…å†µï¼Œè®¾ç½®ä¸ºæ ¹ç›®å½•ä¸‹çš„logç›®å½•
        if not output_path:
            output_path = os.path.join(root_dir, "log")
            
        # åˆ¤æ–­output_pathæ˜¯ç›®å½•è¿˜æ˜¯æ–‡ä»¶å
        if not os.path.splitext(output_path)[1]:
            # æ²¡æœ‰æ–‡ä»¶æ‰©å±•åï¼Œè§†ä¸ºç›®å½•
            output_dir = output_path
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(output_dir, f"batch_train_results_{timestamp}.json")
        else:
            # æœ‰æ–‡ä»¶æ‰©å±•åï¼Œè§†ä¸ºå®Œæ•´æ–‡ä»¶è·¯å¾„
            output_file = output_path
            output_dir = os.path.dirname(os.path.abspath(output_file))
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜ç»“æœ
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æ‰¹é‡è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return output_file
    
    def print_summary(self):
        """æ‰“å°è®­ç»ƒç»“æœæ‘˜è¦ï¼Œå¢å¼ºå¤±è´¥æ¨¡å‹çš„ä¿¡æ¯å±•ç¤º"""
        if not self.results:
            warning("âš ï¸ æ²¡æœ‰è®­ç»ƒç»“æœå¯æ˜¾ç¤ºï¼")
            return
        
        logger.info(f"\n{'='*120}")
        logger.info("ğŸ“Š æ‰¹é‡è®­ç»ƒç»“æœæ‘˜è¦")
        logger.info(f"{'='*120}")
        # ä¿®æ”¹è¡¨æ ¼æ ‡é¢˜ï¼Œæ·»åŠ å¼€å§‹å’Œç»“æŸæ—¶é—´åˆ—
        logger.info(f"{'æ¨¡å‹åç§°':<15} {'æœ€ä½³å‡†ç¡®ç‡':<12} {'è®­ç»ƒæ—¶é—´(ç§’)':<12} {'å¼€å§‹æ—¶é—´':<20} {'ç»“æŸæ—¶é—´':<20} {'çŠ¶æ€'}")

        logger.info(f"{'-'*120}")
        
        # åˆ†å¼€ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„æ¨¡å‹
        successful_models = []
        failed_models = []
        
        for result in self.results:
            status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
            # è·å–å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ˜¾ç¤º"-"
            start_time = result.get("training_start_time", "-")
            end_time = result.get("training_end_time", "-")
            # æ‰“å°åŒ…å«æ—¶é—´ä¿¡æ¯çš„è¡Œï¼Œä¿®æ­£å¯¹é½æ ¼å¼
            logger.info(f"{result['model_name']:<15} {result['best_accuracy']:<12.4f} {result['training_time']:<12.2f} {start_time:<20} {end_time:<20} {status}")
            logger.info("")  # åœ¨æ•°æ®è¡Œä¹‹é—´å¢åŠ ä¸€ä¸ªç©ºè¡Œ
            
            if result["success"]:
                successful_models.append(result)
            else:
                failed_models.append(result)
        
        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„æ•°é‡
        success_count = len(successful_models)
        fail_count = len(failed_models)
        
        logger.info(f"{'-'*120}")
        logger.info(f"æ€»è®¡: {success_count}ä¸ªæˆåŠŸ, {fail_count}ä¸ªå¤±è´¥")
        if success_count > 0:
            avg_accuracy = sum(r["best_accuracy"] for r in successful_models) / success_count
            logger.info(f"å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")
        
        # æ˜¾ç¤ºå¤±è´¥æ¨¡å‹çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯
        if failed_models:
            logger.info(f"\n{'='*60}")
            logger.error("âŒ å¤±è´¥æ¨¡å‹è¯¦æƒ…")
            logger.info(f"{'='*60}")
            for failed_model in failed_models:
                logger.error(f"\næ¨¡å‹åç§°: {failed_model['model_name']}")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {failed_model.get('error', 'æœªçŸ¥é”™è¯¯')}")
                logger.info(f"{'='*60}")
        
        logger.info(f"{'='*60}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="æ‰¹é‡è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹å·¥å…·")
    # ["LeNet","AlexNet","VGG","NIN","GoogLeNet","ResNet","DenseNet"]
    parser.add_argument('--models', type=str, nargs='+', default=["LeNet","LeNet_BatchNorm","AlexNet","VGG","NIN","GoogLeNet","ResNet","DenseNet"], help="æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚ --models LeNet AlexNet")
    parser.add_argument('--skip', type=str, nargs='+', help="æŒ‡å®šè¦è·³è¿‡çš„æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚ --skip VGG ResNet")
    parser.add_argument('--epochs', type=int, help="æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒè½®æ•°")
    parser.add_argument('--lr', type=float, help="æ‰€æœ‰æ¨¡å‹çš„å­¦ä¹ ç‡")
    parser.add_argument('--batch_size', type=int, help="æ‰€æœ‰æ¨¡å‹çš„æ‰¹æ¬¡å¤§å°")
    parser.add_argument('--output_dir', type=str, default='logs', help="è®­ç»ƒç»“æœè¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument('--enable_visualization', action='store_true', help="å¯ç”¨æ¯ä¸ªæ¨¡å‹çš„è®­ç»ƒå¯è§†åŒ–")
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°å…¥å£"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # æ„å»ºé…ç½®å­—å…¸
    configs = {}
    
    # å¦‚æœæŒ‡å®šäº†ç‰¹å®šçš„æ¨¡å‹åˆ—è¡¨ï¼Œåˆ›å»ºè¿™äº›æ¨¡å‹çš„é…ç½®
    if args.models:
        for model_name in args.models:
            if ModelRegistry.is_registered(model_name):
                try:
                    config = ModelRegistry.get_config(model_name)
                    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°çš„å…¨å±€è®¾ç½®
                    if args.epochs is not None:
                        config["num_epochs"] = args.epochs
                    if args.lr is not None:
                        config["lr"] = args.lr
                    if args.batch_size is not None:
                        config["batch_size"] = args.batch_size
                    if args.enable_visualization:
                        config["enable_visualization"] = True
                    
                    configs[model_name] = config
                except ValueError:
                    logger.warning(f"âš ï¸ æ¨¡å‹ '{model_name}' æ²¡æœ‰é»˜è®¤é…ç½®ï¼Œä½¿ç”¨åŸºç¡€é…ç½®")
                    configs[model_name] = {
                        "num_epochs": args.epochs or 10,
                        "lr": args.lr or 0.01,
                        "batch_size": args.batch_size or 128,
                        "resize": None,
                        "input_size": (1, 1, 28, 28),  # é»˜è®¤å°ºå¯¸
                        "enable_visualization": args.enable_visualization
                    }
            else:
                logger.error(f"âŒ æ¨¡å‹ '{model_name}' æœªæ³¨å†Œï¼Œè·³è¿‡")
    else:
        # æ²¡æœ‰æŒ‡å®šæ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æ›´æ–°æ‰€æœ‰æ¨¡å‹çš„é»˜è®¤é…ç½®
        if any([args.epochs is not None, args.lr is not None, args.batch_size is not None]):
            all_models = ModelRegistry.list_models()
            for model_name in all_models:
                if model_name not in (args.skip or []):
                    try:
                        config = ModelRegistry.get_config(model_name)
                        if args.epochs is not None:
                            config["num_epochs"] = args.epochs
                        if args.lr is not None:
                            config["lr"] = args.lr
                        if args.batch_size is not None:
                            config["batch_size"] = args.batch_size
                        if args.enable_visualization:
                            config["enable_visualization"] = True
                        
                        configs[model_name] = config
                    except ValueError:
                        pass  # è·³è¿‡æ²¡æœ‰é»˜è®¤é…ç½®çš„æ¨¡å‹
    
    # åˆ›å»ºæ‰¹é‡è®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    batch_trainer = BatchTrainer(configs=configs, skip_models=args.skip)
    
    # å¦‚æœæŒ‡å®šäº†æ¨¡å‹åˆ—è¡¨ï¼Œåªè®­ç»ƒè¿™äº›æ¨¡å‹
    if args.models:
        valid_models = [m for m in args.models if ModelRegistry.is_registered(m)]
        if not valid_models:
            logger.error(f"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹ï¼è¯·æ£€æŸ¥ --models å‚æ•°")
        else:
            logger.info(f"ğŸ“‹ å¼€å§‹è®­ç»ƒæŒ‡å®šçš„ {len(valid_models)} ä¸ªæ¨¡å‹")
            # ç¡®ä¿å•ä¸ªæ¨¡å‹å¤±è´¥ä¸å½±å“æ•´ä¸ªæ‰¹é‡è®­ç»ƒè¿‡ç¨‹
            for idx, model_name in enumerate(valid_models, 1):
                try:
                    logger.info(f"\nğŸ“Œ å¼€å§‹è®­ç»ƒç¬¬ {idx}/{len(valid_models)} ä¸ªæ¨¡å‹: {model_name}")
                    config = batch_trainer.get_model_config(model_name)
                    batch_trainer.train_model(model_name, config)
                except Exception as e:
                    # é¢å¤–çš„å®‰å…¨ä¿éšœå±‚
                    logger.error(f"âŒ æ¨¡å‹ {model_name} å¤„ç†è¿‡ç¨‹å‡ºç°ä¸¥é‡é”™è¯¯ï¼")
                    logger.exception(f"ğŸ’¬ é”™è¯¯è¯¦æƒ…: {str(e)}")
                    logger.info(f"ğŸ”„ ç»§ç»­è®­ç»ƒä¸‹ä¸€ä¸ªæ¨¡å‹...")
    else:
        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        batch_trainer.train_all_models()
    
    # æ‰“å°ç»“æœæ‘˜è¦
    batch_trainer.print_summary()
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_dir = args.output_dir
    batch_trainer.save_results(output_dir)

if __name__ == "__main__":
    main()