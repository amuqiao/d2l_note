# Transformer翻译流程文字图

## 输入阶段
1. **源语言文本输入**
   - 输入：中文句子 "我爱学习"

## 编码阶段
2. **文本预处理**
   - 源语言嵌入：将每个汉字转换为向量表示
   - 位置编码：添加位置信息，标记词序
3. **Encoder编码**
   - 提取源语言特征表示
   - 捕捉词语间语义关联（如"我-爱-学习"的关系）
   - 生成语义丰富的特征向量

## 解码阶段
4. **Decoder初始化**
   - 初始输入：特殊的"<开始>"标记
   - 准备开始生成目标语言序列
5. **注意力机制处理**
   - 掩码注意力：只关注已生成的词语（防止"偷看"未来信息）
   - 跨注意力：关联Encoder输出的源语言特征
     - 例如：将英文"love"与中文"爱"建立语义对应
6. **特征优化**
   - 前馈网络：进一步优化目标语言特征表示
   - 增强语义表达能力

## 生成阶段
7. **词表概率计算**
   - 输出层：计算目标语言词表中每个词的概率
   - 选择概率最高的词作为当前预测结果（如"love"）
8. **序列循环生成**
   - 将生成的词（"love"）接回Decoder输入
   - 继续生成下一个词
   - 重复此过程直到生成"<结束>"标记
9. **最终译文输出**
   - 组合所有生成的词
   - 输出完整目标语言译文："I love studying"

---

## 流程概览
输入 → 预处理 → 编码 → 解码 → 注意力计算 → 特征优化 → 词预测 → 循环生成 → 最终输出