"""ç½‘ç»œç»“æ„å·¥å…·ç±»"""
import torch
from torch import nn

from src.utils.log_utils.log_utils import get_logger

# åˆå§‹åŒ–æ—¥å¿—å™¨
logger = get_logger(name=__name__, log_file="logs/network_utils.log", global_level="INFO")

class NetworkUtils:
    """ç½‘ç»œç»“æ„å·¥å…·ç±»ï¼šæä¾›ç½‘ç»œç»“æ„æµ‹è¯•ç­‰åŠŸèƒ½"""

    @staticmethod
    def test_network_shape(net, input_size=(1, 1, 28, 28)):
        """æµ‹è¯•ç½‘ç»œå„å±‚è¾“å‡ºå½¢çŠ¶"""
        # æ£€æŸ¥ç½‘ç»œæ˜¯å¦åŒ…å«BatchNormå±‚
        has_batch_norm = NetworkUtils._has_batch_norm(net)
        
        # ä¿å­˜ç½‘ç»œå½“å‰çŠ¶æ€
        is_training = net.training
        net.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        
        try:
            X = torch.rand(size=input_size, dtype=torch.float32)
            model_name = net.__class__.__name__
            logger.info(f"ğŸ” ç½‘ç»œç»“æ„æµ‹è¯• - æ¨¡å‹: {model_name}:")

            # å¦‚æœç½‘ç»œä½¿ç”¨Sequentialå®ç°
            if isinstance(net, nn.Sequential):
                for i, layer in enumerate(net):
                    X = layer(X)
                    logger.info(f"{i+1:2d}. {layer.__class__.__name__:12s} â†’ è¾“å‡ºå½¢çŠ¶: {X.shape}")
            else:
                # ç‰¹å¾æå–å±‚
                logger.info("â”œâ”€ ç‰¹å¾æå–éƒ¨åˆ†:")
                if hasattr(net, "features"):
                    for i, layer in enumerate(net.features):
                        X = layer(X)
                        logger.info(
                            f"â”‚  {i+1:2d}. {layer.__class__.__name__:12s} â†’ è¾“å‡ºå½¢çŠ¶: {X.shape}"
                        )

                # åˆ†ç±»å™¨å±‚
                logger.info("â””â”€ åˆ†ç±»å™¨éƒ¨åˆ†:")
                # å¯¹äºBatchNormç½‘ç»œï¼Œä½¿ç”¨æ‰¹æ¬¡å¤§å°ä¸º2è¿›è¡Œæµ‹è¯•
                if has_batch_norm and input_size[0] == 1:
                    test_input_size = (2,) + input_size[1:]  # ä¸´æ—¶æ”¹ä¸ºæ‰¹æ¬¡å¤§å°2
                    
                else:
                    test_input_size = input_size
                
                X = net.features(torch.rand(size=test_input_size, dtype=torch.float32))
                
                if hasattr(net, "classifier"):
                    for i, layer in enumerate(net.classifier):
                        X = layer(X)
                        logger.info(
                            f"   {i+1:2d}. {layer.__class__.__name__:12s} â†’ è¾“å‡ºå½¢çŠ¶: {X.shape}"
                        )
        finally:
            # æ¢å¤ç½‘ç»œåŸå§‹çŠ¶æ€
            if is_training:
                net.train()
    
    @staticmethod
    def _has_batch_norm(net):
        """æ£€æŸ¥ç½‘ç»œæ˜¯å¦åŒ…å«BatchNormå±‚"""
        for module in net.modules():
            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
                return True
        return False