from typing import List
import matplotlib.pyplot as plt
import numpy as np
import re
import os
import json
from typing import List, Optional, Dict, Any
from src.model_visualization.data_models import ModelInfoData, MetricData
from src.helper_utils.helper_tools_registry import ToolRegistry
from src.utils.log_utils import get_logger
from prettytable import PrettyTable

# å¯¼å…¥åŸºç±»
from src.model_visualization.model_info_visualizers import BaseModelInfoVisualizer

# åˆå§‹åŒ–æ—¥å¿—å™¨
logger = get_logger(name=__name__, log_file="logs/model_info_visualizer.log", global_level="INFO")


class TimestrideModelComparisonVisualizer(BaseModelInfoVisualizer):
    """Timestrideæ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒå¯è§†åŒ–å™¨ï¼šä¸“æ³¨äºæ¯”è¾ƒtimestrideå‘½åç©ºé—´ä¸‹å¤šä¸ªæ¨¡å‹çš„å‡†ç¡®ç‡æŒ‡æ ‡"""
    
    def __init__(self):
        self.model_infos = []
        # æ–°å¢ï¼šè®¾ç½®æ’åºæ–¹å¼
        self.sort_by = "accuracy"  # é»˜è®¤æŒ‰å‡†ç¡®ç‡æ’åº
        self.namespace = "timestride"
    
    def support(self, model_info: ModelInfoData) -> bool:
        # è¿™ä¸ªå¯è§†åŒ–å™¨éœ€è¦è‡³å°‘åŒ…å«å‡†ç¡®ç‡ä¿¡æ¯çš„æ¨¡å‹
        return model_info.namespace == self.namespace
    
    def add_model_info(self, model_info: ModelInfoData):
        """æ·»åŠ è¦æ¯”è¾ƒçš„æ¨¡å‹ä¿¡æ¯"""
        if self.support(model_info):
            self.model_infos.append(model_info)
        else:
            logger.warning(f"æ¨¡å‹ {model_info.path} ä¸å±äºtimestrideå‘½åç©ºé—´ï¼Œä¸æ·»åŠ åˆ°æ¯”è¾ƒåˆ—è¡¨")
    
    def set_sort_by(self, sort_by: str):
        """è®¾ç½®æ’åºæ–¹å¼
        
        å‚æ•°:
            sort_by: æ’åºä¾æ®ï¼Œå¯é€‰å€¼: "accuracy" (æŒ‰å‡†ç¡®ç‡) æˆ– "name" (æŒ‰åç§°)
        """
        if sort_by in ["accuracy", "name"]:
            self.sort_by = sort_by
        else:
            logger.warning(f"æ— æ•ˆçš„æ’åºæ–¹å¼: {sort_by}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 'accuracy'")
    
    def visualize(self, model_info: ModelInfoData = None, show: bool = True, 
                  figsize: tuple = (15, 10), plot_type: str = "all") -> Optional[object]:
        """
        å¯è§†åŒ–æ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒ
        
        å‚æ•°:
            model_info: å¯é€‰çš„æ¨¡å‹ä¿¡æ¯å¯¹è±¡
            show: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨/è¡¨æ ¼
            figsize: å›¾è¡¨å¤§å°ï¼ˆè¡¨æ ¼æ¨¡å¼ä¸‹å¿½ç•¥ï¼‰
            plot_type: æ¯”è¾ƒç±»å‹ï¼Œå¯é€‰å€¼: "all" (å…¨éƒ¨), "ranking" (æ’åè¡¨æ ¼)
        
        è¿”å›:
            è¡¨æ ¼å¯¹è±¡æˆ–None
        """
        try:
            # å¦‚æœä¼ å…¥äº†model_infoï¼Œæ·»åŠ åˆ°æ¯”è¾ƒåˆ—è¡¨
            if model_info:
                self.add_model_info(model_info)
            
            # ç¡®ä¿æœ‰æ¨¡å‹å¯ä»¥æ¯”è¾ƒ
            if len(self.model_infos) < 2:
                logger.warning("æ¨¡å‹æ¯”è¾ƒéœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹ä¿¡æ¯")
                return None
            
            # å‡†å¤‡æ¯”è¾ƒæ•°æ®
            model_data = []
            
            for info in self.model_infos:
                # è·å–æ¨¡å‹åç§°æˆ–æ ‡è¯†ç¬¦
                model_name = self._get_model_name(info)
                
                # è·å–æµ‹è¯•å‡†ç¡®ç‡
                test_acc = info.metrics.get("accuracy", 0)
                
                # å°è¯•ä»training_metrics.jsonè·å–æ›´å¤šæŒ‡æ ‡
                train_acc = 0
                val_acc = 0
                train_loss = 0
                val_loss = 0
                epochs = 0
                
                # ä»è·¯å¾„ä¸­è§£æä¸€äº›å‚æ•°ä¿¡æ¯
                model_path = info.path
                
                # ä»é…ç½®å‚æ•°ä¸­è·å–ä¿¡æ¯
                model_type = info.params.get("model", "Unknown")
                seq_len = info.params.get("seq_len", "Unknown")
                d_model = info.params.get("d_model", "Unknown")
                n_heads = info.params.get("n_heads", "Unknown")
                
                model_data.append({
                    "name": model_name,
                    "test_acc": test_acc,
                    "train_acc": train_acc,
                    "val_acc": val_acc,
                    "model_type": model_type,
                    "seq_len": seq_len,
                    "d_model": d_model,
                    "n_heads": n_heads,
                    "train_loss": train_loss,
                    "val_loss": val_loss,
                    "epochs": epochs,
                    "path": info.path
                })
            
            # æ ¹æ®æ’åºæ–¹å¼æ’åº
            if self.sort_by == "accuracy":
                model_data.sort(key=lambda x: x["test_acc"], reverse=True)
            else:
                model_data.sort(key=lambda x: x["name"])
            
            # å®ç°rankingæ¨¡å¼ï¼ˆè¡¨æ ¼è¾“å‡ºï¼‰
            if plot_type == "ranking" or plot_type == "all":
                # ä½¿ç”¨PrettyTableåˆ›å»ºè¡¨æ ¼
                table = PrettyTable()
                
                # è®¾ç½®è¡¨æ ¼æ ‡é¢˜
                print("\n" + "="*80)
                print("ğŸ“Š Timestrideæ¨¡å‹å‡†ç¡®ç‡è¯¦ç»†æ’åæ¯”è¾ƒ")
                print("="*80)
                
                # è®¾ç½®è¡¨æ ¼å­—æ®µ
                table.field_names = ["æ’å", "æ¨¡å‹åç§°", "æ¨¡å‹ç±»å‹", "æµ‹è¯•å‡†ç¡®ç‡", "åºåˆ—é•¿åº¦", "åµŒå…¥ç»´åº¦", "æ³¨æ„åŠ›å¤´æ•°", "æ¥æºè·¯å¾„"]
                
                # è®¾ç½®è¡¨æ ¼å¯¹é½æ–¹å¼
                table.align["æ¨¡å‹åç§°"] = "l"  # å·¦å¯¹é½
                table.align["æ¨¡å‹ç±»å‹"] = "l"
                table.align["æµ‹è¯•å‡†ç¡®ç‡"] = "r"
                table.align["åºåˆ—é•¿åº¦"] = "r"
                table.align["åµŒå…¥ç»´åº¦"] = "r"
                table.align["æ³¨æ„åŠ›å¤´æ•°"] = "r"
                
                # æ·»åŠ æ•°æ®è¡Œ
                for i, data in enumerate(model_data, 1):
                    # æ ¼å¼åŒ–è·¯å¾„ï¼ˆåªæ˜¾ç¤ºæœ€åä¸¤çº§ç›®å½•ï¼‰
                    path_parts = data['path'].split('/')[-3:]
                    short_path = '/'.join(path_parts)
                    
                    # æ·»åŠ è¡Œæ•°æ®
                    table.add_row([
                        i,
                        data['name'],
                        data['model_type'],
                        f"{data['test_acc']:.4f}",
                        data['seq_len'],
                        data['d_model'],
                        data['n_heads'],
                        short_path
                    ])
                
                # è®¾ç½®è¡¨æ ¼æ ·å¼
                table.border = True
                table.header = True
                table.padding_width = 1
                
                # æ‰“å°è¡¨æ ¼
                if show:
                    print(table)
                    
                    # æ·»åŠ æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯
                    test_accs = [d["test_acc"] for d in model_data]
                    max_acc_idx = test_accs.index(max(test_accs))
                    min_acc_idx = test_accs.index(min(test_accs))
                    
                    print("\n" + "="*80)
                    print("ğŸ“‹ æ¨¡å‹æ¯”è¾ƒæ‘˜è¦")
                    print("="*80)
                    print(f"ğŸ† æœ€ä½³æ¨¡å‹: {model_data[max_acc_idx]['name']} (å‡†ç¡®ç‡: {test_accs[max_acc_idx]:.4f})")
                    print(f"ğŸ“‰ æœ€å·®æ¨¡å‹: {model_data[min_acc_idx]['name']} (å‡†ç¡®ç‡: {test_accs[min_acc_idx]:.4f})")
                    print(f"ğŸ“Š å¹³å‡å‡†ç¡®ç‡: {sum(test_accs) / len(test_accs):.4f}")
                    print(f"ğŸ“ å‡†ç¡®ç‡èŒƒå›´: {max(test_accs) - min(test_accs):.4f}")
                    print("="*80)
                
                return table
            else:
                logger.info(f"æ¨¡å¼ '{plot_type}' å°šæœªå®ç°è¡¨æ ¼è¾“å‡º")
                print(f"âš ï¸ è­¦å‘Šï¼š'{plot_type}' æ¨¡å¼å°šæœªå®ç°è¡¨æ ¼è¾“å‡ºï¼Œè¯·ä½¿ç”¨ 'ranking' æ¨¡å¼")
                return None
            
        except Exception as e:
            logger.error(f"ç»˜åˆ¶æ¨¡å‹æ¯”è¾ƒå¯è§†åŒ–å¤±è´¥: {str(e)}")
            print(f"âŒ æ¨¡å‹æ¯”è¾ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
            return None
    
    def _get_model_name(self, model_info: ModelInfoData) -> str:
        """è·å–æœ‰æ„ä¹‰çš„æ¨¡å‹åç§°"""
        # å°è¯•ä»è·¯å¾„ä¸­æå–æ¨¡å‹åç§°
        path_basename = os.path.basename(model_info.path)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨¡å‹åç§°å…³é”®å­—
        model_types = ["TimesNet", "Transformer", "LSTM", "GRU", "CNN"]
        for model_type in model_types:
            if model_type.lower() in path_basename.lower():
                # å°è¯•æå–ä¸€äº›å…³é”®å‚æ•°ä¿¡æ¯
                seq_len_match = re.search(r'sl(\d+)', path_basename)
                d_model_match = re.search(r'dm(\d+)', path_basename)
                
                name_parts = [model_type]
                if seq_len_match:
                    name_parts.append(f"sl{seq_len_match.group(1)}")
                if d_model_match:
                    name_parts.append(f"dm{d_model_match.group(1)}")
                
                return "-".join(name_parts)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜æ˜¾çš„æ¨¡å‹ç±»å‹ï¼Œæˆªå–è·¯å¾„å
        if len(path_basename) > 20:
            return path_basename[:17] + '...'
        return path_basename
    
    def create_model_info_from_path(self, model_path: str) -> Optional[ModelInfoData]:
        """ä»æ¨¡å‹è·¯å¾„åˆ›å»ºModelInfoDataå¯¹è±¡"""
        try:
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                logger.warning(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
                return None
            
            # åˆå§‹åŒ–å‚æ•°å’ŒæŒ‡æ ‡
            params = {}
            metrics = {}
            
            # å°è¯•è¯»å–args.json
            args_path = os.path.join(model_path, "args.json")
            if os.path.exists(args_path):
                with open(args_path, 'r') as f:
                    params = json.load(f)
            
            # å°è¯•è¯»å–test_results/metrics.json
            test_metrics_path = os.path.join(model_path, "test_results", "metrics.json")
            if os.path.exists(test_metrics_path):
                with open(test_metrics_path, 'r') as f:
                    test_metrics = json.load(f)
                    metrics.update(test_metrics)
            
            # å°è¯•ä»training_metrics.jsonè·å–æ›´å¤šæŒ‡æ ‡
            train_metrics_path = os.path.join(model_path, "training_metrics.json")
            if os.path.exists(train_metrics_path):
                with open(train_metrics_path, 'r') as f:
                    train_metrics = json.load(f)
                    # è·å–æœ€åä¸€ä¸ªepochçš„æŒ‡æ ‡
                    if train_metrics and isinstance(train_metrics, list) and len(train_metrics) > 0:
                        last_epoch = train_metrics[-1]
                        if "test_accuracy" in last_epoch:
                            metrics["accuracy"] = last_epoch["test_accuracy"]
            
            # æå–æ¨¡å‹ç±»å‹
            model_type = params.get("model", "Unknown")
            
            # åˆ›å»ºModelInfoDataå¯¹è±¡
            model_info = ModelInfoData(
                type="model",
                path=model_path,
                model_type=model_type,
                params=params,
                metrics=metrics,
                timestamp=os.path.getmtime(model_path),
                namespace=self.namespace
            )
            
            return model_info
        except Exception as e:
            logger.error(f"ä»è·¯å¾„åˆ›å»ºæ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

# æ³¨å†Œå¯è§†åŒ–å™¨åˆ°timestrideå‘½åç©ºé—´
from src.model_visualization.model_info_visualizers import ModelInfoVisualizerRegistry
ModelInfoVisualizerRegistry.register(TimestrideModelComparisonVisualizer(), namespace="timestride")