import os
import sys
import time
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.model_visualization.model_info_parsers import ModelInfoParserRegistry, register_parsers
from src.model_visualization.model_info_visualizers_impl import ModelComparisonVisualizer

# æ³¨å†Œè§£æå™¨
register_parsers()

def create_test_model_info():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡å‹ä¿¡æ¯æ•°æ®"""
    # æ¨¡æ‹Ÿåˆ›å»ºå‡ ä¸ªæ¨¡å‹ä¿¡æ¯å¯¹è±¡ç”¨äºæµ‹è¯•
    from src.model_visualization.data_models import ModelInfoData
    
    # è·å–å½“å‰æ—¶é—´æˆ³
    current_timestamp = time.time()
    
    # æ¨¡å‹1
    model1 = ModelInfoData(
        type="metrics",
        path="runs/test_model1",
        model_type="ResNet-18",
        params={"total_params": 11689512, "model_type": "ResNet-18"},
        metrics={
            "final_test_acc": 0.9256,
            "final_train_acc": 0.9532,
            "best_val_acc": 0.9312,
            "total_training_time": "1234.5 seconds"
        },
        timestamp=current_timestamp - 3600,  # 1å°æ—¶å‰
        namespace="test"
    )
    
    # æ¨¡å‹2
    model2 = ModelInfoData(
        type="metrics",
        path="runs/test_model2",
        model_type="VGG-16",
        params={"total_params": 138357544, "model_type": "VGG-16"},
        metrics={
            "final_test_acc": 0.9421,
            "final_train_acc": 0.9876,
            "best_val_acc": 0.9513,
            "total_training_time": "2345.6 seconds"
        },
        timestamp=current_timestamp - 7200,  # 2å°æ—¶å‰
        namespace="test"
    )
    
    # æ¨¡å‹3
    model3 = ModelInfoData(
        type="metrics",
        path="runs/test_model3",
        model_type="AlexNet",
        params={"total_params": 61100840, "model_type": "AlexNet"},
        metrics={
            "final_test_acc": 0.8975,
            "final_train_acc": 0.9234,
            "best_val_acc": 0.9012,
            "total_training_time": "876.5 seconds"
        },
        timestamp=current_timestamp - 10800,  # 3å°æ—¶å‰
        namespace="test"
    )
    
    return [model1, model2, model3]

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*80)
    print("ğŸ§ª æ¨¡å‹æ¯”è¾ƒè¡¨æ ¼è¾“å‡ºæµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    model_infos = create_test_model_info()
    
    # åˆ›å»ºæ¯”è¾ƒå¯è§†åŒ–å™¨
    visualizer = ModelComparisonVisualizer()
    
    # æ·»åŠ æ¨¡å‹ä¿¡æ¯
    for model_info in model_infos:
        visualizer.add_model_info(model_info)
    
    # è®¾ç½®æŒ‰å‡†ç¡®ç‡æ’åº
    visualizer.set_sort_by("accuracy")
    
    # ä½¿ç”¨rankingæ¨¡å¼è¿›è¡Œå¯è§†åŒ–ï¼ˆè¡¨æ ¼è¾“å‡ºï¼‰
    print("\nğŸ“Š æµ‹è¯•rankingæ¨¡å¼ï¼ˆæŒ‰å‡†ç¡®ç‡æ’åºï¼‰:")
    table = visualizer.visualize(show=True, plot_type="ranking")
    
    # æµ‹è¯•æŒ‰åç§°æ’åº
    visualizer = ModelComparisonVisualizer()  # åˆ›å»ºæ–°çš„å¯è§†åŒ–å™¨
    for model_info in model_infos:
        visualizer.add_model_info(model_info)
    visualizer.set_sort_by("name")
    
    print("\nğŸ“Š æµ‹è¯•rankingæ¨¡å¼ï¼ˆæŒ‰åç§°æ’åºï¼‰:")
    table = visualizer.visualize(show=True, plot_type="ranking")
    
    # æµ‹è¯•å…¶ä»–æ¨¡å¼ï¼ˆåº”è¯¥æ˜¾ç¤ºè­¦å‘Šï¼‰
    print("\nğŸ“Š æµ‹è¯•å…¶ä»–æ¨¡å¼ï¼ˆåº”è¯¥æ˜¾ç¤ºè­¦å‘Šï¼‰:")
    table = visualizer.visualize(show=True, plot_type="bar")
    
    print("\n" + "="*80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("="*80)

if __name__ == "__main__":
    main()