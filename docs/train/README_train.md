# train.py 模块文档

## 功能介绍

`train.py` 是一个模型训练脚本，提供了完整的深度学习模型训练流程，包括模型初始化、训练循环、评估、模型保存和结果可视化等功能。该脚本作为系统的核心训练入口，允许用户通过命令行参数灵活配置训练参数。

## 主要组件

### 1. 核心功能
- 命令行参数解析，支持自定义学习率、批次大小、训练轮次等参数
- 自动选择最佳可用设备（GPU/CPU）
- 完整的训练流程管理（数据加载、模型训练、评估、保存）
- 实时训练可视化
- 训练结果记录与分析
- 训练后预测可视化

### 2. 主要依赖
- `src.utils.log_utils`: 日志功能
- `src.trainer.trainer`: 训练器类实现
- `src.utils.model_registry`: 模型注册表
- `src.configs.model_configs`: 模型默认配置
- `d2l`: 深度学习工具库
- `torch`: PyTorch深度学习框架

## 使用方法

### 基本用法

```bash
python train.py
```

这将使用默认参数（LeNet模型，学习率0.8，批次大小256，训练3轮）启动训练。

### 命令行参数

`train.py` 支持以下命令行参数来自定义训练配置：

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model-type` | str | `LeNet` | 模型类型，可选值：LeNet, AlexNet, VGG, NIN, GoogLeNet |
| `--lr` | float | - | 学习率，不设置则使用模型默认值 |
| `--batch-size` | int | - | 批次大小，不设置则使用模型默认值 |
| `--num-epochs` | int | - | 训练轮次，不设置则使用模型默认值 |
| `--disable-visualization` | flag | False | 是否禁用实时可视化 |
| `--save-every-epoch` | flag | False | 是否保存每一轮的模型 |

### 示例

使用AlexNet模型，学习率0.01，批次大小128，训练10轮：

```bash
python train.py --model-type AlexNet --lr 0.01 --batch-size 128 --num-epochs 10
```

禁用可视化但保存每轮模型：

```bash
python train.py --disable-visualization --save-every-epoch
```

## 训练流程

1. **初始化阶段**
   - 解析命令行参数
   - 设置日志系统
   - 加载模型配置
   - 初始化Trainer实例

2. **数据准备阶段**
   - 根据模型类型加载相应的数据集（Fashion-MNIST）
   - 应用适当的数据预处理（如调整图像大小）

3. **训练执行阶段**
   - 执行训练循环（每轮包括训练和评估）
   - 实时可视化训练过程
   - 保存最佳模型和每轮模型（可选）
   - 记录训练指标

4. **训练后处理阶段**
   - 输出训练总结
   - 执行预测可视化

## 输出文件

训练完成后，会在当前目录下生成一个带有时间戳的训练目录，包含以下文件：

- `config.json`: 训练配置信息
- `metrics.json`: 完整的训练指标，包括每轮的损失、准确率和总训练时间
- `epoch_metrics.json`: 每轮训练的详细指标历史
- `best_model_*.pth`: 表现最佳的模型权重文件
- `epoch_model_*.pth`: 各轮次的模型权重文件（如果启用了`--save-every-epoch`）

## 最佳实践

1. **设备选择**
   - 脚本会自动检测并使用可用的GPU（如果存在），否则使用CPU
   - 对于大型模型（如VGG），建议在GPU环境下运行以提高训练速度

2. **参数调优**
   - 对于不同的模型，建议使用`model_configs.py`中定义的默认参数作为起点
   - 如需调整学习率，可以尝试在默认值的基础上乘以0.1或10进行微调
   - 训练轮次可以根据模型收敛情况适当增减

3. **可视化与日志**
   - 默认情况下启用实时可视化，有助于监控训练进度
   - 训练过程中的所有重要事件都会记录到日志中，包括模型保存、评估结果等

4. **模型保存**
   - 默认只保存表现最佳的模型，以节省存储空间
   - 如需保留每一轮的模型用于分析或比较，可以使用`--save-every-epoch`参数

## 常见问题

1. **CUDA内存不足**
   - 减小批次大小（`--batch-size`）
   - 对于大型模型，考虑使用更小的输入尺寸或简化模型结构

2. **训练不稳定**
   - 降低学习率（`--lr`）
   - 检查数据预处理是否正确

3. **可视化不显示**
   - 确保安装了必要的可视化库
   - 如不需要可视化，可使用`--disable-visualization`参数禁用

## 代码结构

`train.py` 的核心代码结构如下：

```python
# 1. 初始化日志
logger = get_logger(name="train", log_file="logs/train.log", global_level="DEBUG")

# 2. 解析命令行参数
def parse_arguments():
    # 参数解析逻辑

# 3. 主函数
def main():
    # 解析参数
    # 加载配置
    # 初始化Trainer
    # 加载数据
    # 执行训练
    # 执行后处理

# 4. 执行入口
if __name__ == "__main__":
    main()
```

## 扩展指南

如需扩展`train.py`的功能，可以考虑以下方向：

1. 添加新的命令行参数以支持更多配置选项
2. 集成更多的数据集加载功能
3. 增加模型评估指标（如精确率、召回率等）
4. 添加早停机制以防止过拟合
5. 实现学习率调度器以优化训练过程

---

**版本信息**: v1.0
**最后更新**: 2024-05-20